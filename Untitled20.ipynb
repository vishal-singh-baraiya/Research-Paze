{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNr//tKNS8AK6ubyQo4T5Xd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vishal-singh-baraiya/Research-Paze/blob/main/Untitled20.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R2OKI_rUPCdP",
        "outputId": "40d3a1e5-1a60-41fa-c0c0-e6e57ad2625d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading test data...\n",
            "Loading model...\n",
            "Running predictions...\n",
            "Saved predictions to /content/submission.csv\n",
            "       id          Tg       FFV        Tc   Density         Rg\n",
            "0   87817   51.146648  0.370435  0.225358  0.963353  13.223957\n",
            "1  106919   84.518524  0.386128  0.223477  0.891822  14.156920\n",
            "2  388772  164.671814  0.367750  0.186437  1.175212  15.896211\n",
            "3  519416  129.284302  0.375045  0.199667  0.999432  15.399435\n",
            "4  539187   53.881340  0.375350  0.240403  1.061078  15.860585\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.loader import DataLoader as PyGDataLoader\n",
        "from torch_geometric.nn import GATv2Conv, global_mean_pool\n",
        "from rdkit import Chem\n",
        "\n",
        "# ---------------- Configuration ----------------\n",
        "class Config:\n",
        "    TEST_PATH = '/content/train.csv'\n",
        "    SUBMISSION_PATH = '/content/submission.csv'\n",
        "    GRAPH_CACHE_DIR = 'graph_cache'\n",
        "    DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    BATCH_SIZE = 128\n",
        "    TARGET_PROPERTIES = ['Tg', 'FFV', 'Tc', 'Density', 'Rg']\n",
        "\n",
        "config = Config()\n",
        "\n",
        "# -------------- Graph Featurization --------------\n",
        "def get_atom_features(atom):\n",
        "    features = [\n",
        "        atom.GetAtomicNum(),\n",
        "        atom.GetDegree(),\n",
        "        atom.GetFormalCharge(),\n",
        "        atom.GetHybridization(),\n",
        "        atom.GetIsAromatic(),\n",
        "        atom.GetNumRadicalElectrons(),\n",
        "        atom.IsInRing()\n",
        "    ]\n",
        "    hybridization = [0] * 5\n",
        "    try:\n",
        "        hybridization[int(atom.GetHybridization())] = 1\n",
        "    except:\n",
        "        pass\n",
        "    return torch.tensor(features + hybridization, dtype=torch.float)\n",
        "\n",
        "def get_bond_features(bond):\n",
        "    features = [int(bond.GetBondType()), bond.GetIsConjugated(), bond.IsInRing()]\n",
        "    return torch.tensor(features, dtype=torch.float)\n",
        "\n",
        "def smiles_to_graph(smiles_string, idx):\n",
        "    mol = Chem.MolFromSmiles(smiles_string)\n",
        "    if mol is None:\n",
        "        return Data(x=torch.zeros((1, 12)), edge_index=torch.empty((2, 0), dtype=torch.long), id=idx)\n",
        "\n",
        "    atom_features = [get_atom_features(atom) for atom in mol.GetAtoms()]\n",
        "    x = torch.stack(atom_features)\n",
        "\n",
        "    edge_indices, edge_attrs = [], []\n",
        "    for bond in mol.GetBonds():\n",
        "        i, j = bond.GetBeginAtomIdx(), bond.GetEndAtomIdx()\n",
        "        edge_indices.extend([(i, j), (j, i)])\n",
        "        bond_feats = get_bond_features(bond)\n",
        "        edge_attrs.extend([bond_feats, bond_feats])\n",
        "\n",
        "    if not edge_indices:\n",
        "        edge_index = torch.empty((2, 0), dtype=torch.long)\n",
        "        edge_attr = torch.empty((0, 3), dtype=torch.float)\n",
        "    else:\n",
        "        edge_index = torch.tensor(edge_indices, dtype=torch.long).t().contiguous()\n",
        "        edge_attr = torch.stack(edge_attrs)\n",
        "\n",
        "    return Data(x=x, edge_index=edge_index, edge_attr=edge_attr, smiles=smiles_string, id=idx)\n",
        "\n",
        "# -------------- Dataset Wrapper --------------\n",
        "class PolymerTestDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, df):\n",
        "        self.smiles = df['SMILES'].values\n",
        "        self.ids = df['id'].values\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.smiles)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        graph_path = os.path.join(config.GRAPH_CACHE_DIR, f\"graph_{self.ids[idx]}.pt\")\n",
        "        if os.path.exists(graph_path):\n",
        "            graph = torch.load(graph_path, weights_only=False)\n",
        "        else:\n",
        "            graph = smiles_to_graph(self.smiles[idx], self.ids[idx])\n",
        "            torch.save(graph, graph_path)\n",
        "        return graph, torch.tensor([0.0])  # Dummy target\n",
        "\n",
        "# -------------- Model Definition --------------\n",
        "class PolymerGNN(nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels, num_layers, heads, dropout):\n",
        "        super(PolymerGNN, self).__init__()\n",
        "        self.convs = nn.ModuleList()\n",
        "        self.convs.append(GATv2Conv(in_channels, hidden_channels, heads=heads, dropout=dropout, concat=True))\n",
        "        for _ in range(num_layers - 2):\n",
        "            self.convs.append(GATv2Conv(hidden_channels * heads, hidden_channels, heads=heads, dropout=dropout, concat=True))\n",
        "        self.convs.append(GATv2Conv(hidden_channels * heads, hidden_channels, heads=1, dropout=dropout, concat=False))\n",
        "\n",
        "        self.prediction_heads = nn.ModuleList([\n",
        "            nn.Sequential(\n",
        "                nn.Linear(hidden_channels, hidden_channels // 2),\n",
        "                nn.ReLU(),\n",
        "                nn.Dropout(p=dropout),\n",
        "                nn.Linear(hidden_channels // 2, 1)\n",
        "            ) for _ in range(len(config.TARGET_PROPERTIES))\n",
        "        ])\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
        "        for i, conv in enumerate(self.convs):\n",
        "            x = conv(x, edge_index)\n",
        "            if i < len(self.convs) - 1:\n",
        "                x = torch.relu(x)\n",
        "        x = global_mean_pool(x, batch)\n",
        "        outputs = [head(x) for head in self.prediction_heads]\n",
        "        return torch.cat(outputs, dim=1)\n",
        "\n",
        "# -------------- Inference --------------\n",
        "def run_inference():\n",
        "    print(\"Loading test data...\")\n",
        "    test_df = pd.read_csv(config.TEST_PATH)\n",
        "    dataset = PolymerTestDataset(test_df)\n",
        "    loader = PyGDataLoader(dataset, batch_size=config.BATCH_SIZE, shuffle=False)\n",
        "\n",
        "    # Get input dimension from one sample\n",
        "    sample_graph, _ = dataset[0]\n",
        "    in_channels = sample_graph.x.shape[1]\n",
        "\n",
        "    print(\"Loading model...\")\n",
        "    model = PolymerGNN(\n",
        "        in_channels=in_channels,\n",
        "        hidden_channels=256,\n",
        "        out_channels=len(config.TARGET_PROPERTIES),\n",
        "        num_layers=4,\n",
        "        heads=8,\n",
        "        dropout=0.2\n",
        "    ).to(config.DEVICE)\n",
        "    model.load_state_dict(torch.load('best_model.pth', map_location=config.DEVICE))\n",
        "    model.eval()\n",
        "\n",
        "    print(\"Running predictions...\")\n",
        "    all_preds = []\n",
        "    with torch.no_grad():\n",
        "        for batch_graphs, _ in loader:\n",
        "            batch_graphs = batch_graphs.to(config.DEVICE)\n",
        "            preds = model(batch_graphs)\n",
        "            all_preds.append(preds.cpu().numpy())\n",
        "\n",
        "    predictions = np.vstack(all_preds)\n",
        "    submission = pd.DataFrame(predictions, columns=config.TARGET_PROPERTIES)\n",
        "    submission.insert(0, 'id', test_df['id'])\n",
        "    submission.to_csv(config.SUBMISSION_PATH, index=False)\n",
        "    print(f\"Saved predictions to {config.SUBMISSION_PATH}\")\n",
        "    print(submission.head())\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    if not os.path.exists(config.TEST_PATH):\n",
        "        print(\"Error: test.csv not found.\")\n",
        "    else:\n",
        "        os.makedirs(config.GRAPH_CACHE_DIR, exist_ok=True)\n",
        "        run_inference()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# Step 0: Initial Setup and Imports\n",
        "# ==============================================================================\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.loader import DataLoader as PyGDataLoader\n",
        "from torch_geometric.nn import GATv2Conv, global_mean_pool\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import AllChem\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import gc\n",
        "\n",
        "# For reproducibility\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(42)\n",
        "\n",
        "# ==============================================================================\n",
        "# Step 1: Configuration\n",
        "# ==============================================================================\n",
        "class Config:\n",
        "    \"\"\"Holds all hyperparameters and configuration settings.\"\"\"\n",
        "    # Data paths\n",
        "    TRAIN_PATH = '/kaggle/input/neurips-open-polymer-prediction-2025/train.csv'\n",
        "    TEST_PATH = '/kaggle/input/neurips-open-polymer-prediction-2025/test.csv'\n",
        "    SUBMISSION_PATH = 'submission.csv'\n",
        "\n",
        "    # Model and training parameters\n",
        "    DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    EPOCHS = 30  # Number of training epochs\n",
        "    BATCH_SIZE = 128 # Batch size for training and inference\n",
        "    LEARNING_RATE = 1e-3 # Optimizer learning rate\n",
        "    WEIGHT_DECAY = 1e-5 # Weight decay for regularization\n",
        "    HIDDEN_CHANNELS = 256 # Number of hidden channels in GNN layers\n",
        "    NUM_GNN_LAYERS = 4 # Number of GNN layers\n",
        "    NUM_ATTENTION_HEADS = 8 # Number of attention heads in GATv2\n",
        "    DROPOUT_RATE = 0.2 # Dropout rate for regularization\n",
        "    VALIDATION_SPLIT = 0.2 # Percentage of training data to use for validation\n",
        "\n",
        "    # Target properties to predict\n",
        "    TARGET_PROPERTIES = ['Tg', 'FFV', 'Tc', 'Density', 'Rg']\n",
        "    NUM_TARGETS = len(TARGET_PROPERTIES)\n",
        "\n",
        "    # Pre-computation flag\n",
        "    PRECOMPUTE_GRAPHS = True # If True, pre-compute and save graphs to disk\n",
        "    GRAPH_CACHE_DIR = 'graph_cache'\n",
        "\n",
        "config = Config()\n",
        "print(f\"Using device: {config.DEVICE}\")\n",
        "\n",
        "# Create cache directory if it doesn't exist\n",
        "if config.PRECOMPUTE_GRAPHS and not os.path.exists(config.GRAPH_CACHE_DIR):\n",
        "    os.makedirs(config.GRAPH_CACHE_DIR)\n",
        "\n",
        "# ==============================================================================\n",
        "# Step 2: Graph Featurization from SMILES\n",
        "# ==============================================================================\n",
        "\n",
        "def get_atom_features(atom):\n",
        "    \"\"\" Extracts features from an RDKit atom object. \"\"\"\n",
        "    features = [\n",
        "        atom.GetAtomicNum(),\n",
        "        atom.GetDegree(),\n",
        "        atom.GetFormalCharge(),\n",
        "        atom.GetHybridization(),\n",
        "        atom.GetIsAromatic(),\n",
        "        atom.GetNumRadicalElectrons(),\n",
        "        atom.IsInRing(),\n",
        "    ]\n",
        "    hybridization = [0] * 5\n",
        "    try:\n",
        "        hybridization[int(atom.GetHybridization())] = 1\n",
        "    except:\n",
        "        pass\n",
        "    return torch.tensor(features + hybridization, dtype=torch.float)\n",
        "\n",
        "def get_bond_features(bond):\n",
        "    \"\"\" Extracts features from an RDKit bond object. \"\"\"\n",
        "    features = [int(bond.GetBondType()), bond.GetIsConjugated(), bond.IsInRing()]\n",
        "    return torch.tensor(features, dtype=torch.float)\n",
        "\n",
        "def smiles_to_graph(smiles_string, idx):\n",
        "    \"\"\" Converts a SMILES string to a PyTorch Geometric Data object. \"\"\"\n",
        "    mol = Chem.MolFromSmiles(smiles_string)\n",
        "    if mol is None:\n",
        "        print(f\"Warning: RDKit could not parse SMILES: {smiles_string} at index {idx}\")\n",
        "        return None\n",
        "\n",
        "    atom_features = [get_atom_features(atom) for atom in mol.GetAtoms()]\n",
        "    x = torch.stack(atom_features)\n",
        "\n",
        "    edge_indices, edge_attrs = [], []\n",
        "    for bond in mol.GetBonds():\n",
        "        i, j = bond.GetBeginAtomIdx(), bond.GetEndAtomIdx()\n",
        "        edge_indices.extend([(i, j), (j, i)])\n",
        "        bond_feats = get_bond_features(bond)\n",
        "        edge_attrs.extend([bond_feats, bond_feats])\n",
        "\n",
        "    if not edge_indices:\n",
        "        edge_index = torch.empty((2, 0), dtype=torch.long)\n",
        "        edge_attr = torch.empty((0, 3), dtype=torch.float)\n",
        "    else:\n",
        "        edge_index = torch.tensor(edge_indices, dtype=torch.long).t().contiguous()\n",
        "        edge_attr = torch.stack(edge_attrs)\n",
        "\n",
        "    return Data(x=x, edge_index=edge_index, edge_attr=edge_attr, smiles=smiles_string, id=idx)\n",
        "\n",
        "# ==============================================================================\n",
        "# Step 3: Custom PyTorch Geometric Dataset\n",
        "# ==============================================================================\n",
        "\n",
        "class PolymerDataset(Dataset):\n",
        "    def __init__(self, df, targets=None, is_train=True):\n",
        "        self.df = df\n",
        "        self.smiles = df['SMILES'].values\n",
        "        self.ids = df['id'].values\n",
        "        self.is_train = is_train\n",
        "        self.targets = targets if targets is not None else np.full((len(df), config.NUM_TARGETS), np.nan)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        graph_path = os.path.join(config.GRAPH_CACHE_DIR, f\"graph_{self.ids[idx]}.pt\")\n",
        "\n",
        "        if config.PRECOMPUTE_GRAPHS and os.path.exists(graph_path):\n",
        "            graph = torch.load(graph_path, weights_only=False)\n",
        "        else:\n",
        "            graph = smiles_to_graph(self.smiles[idx], self.ids[idx])\n",
        "            if graph is None:\n",
        "                graph = Data(x=torch.zeros((1, 12)), edge_index=torch.empty((2, 0), dtype=torch.long))\n",
        "            if config.PRECOMPUTE_GRAPHS:\n",
        "                torch.save(graph, graph_path)\n",
        "\n",
        "        target = torch.tensor(self.targets[idx], dtype=torch.float)\n",
        "        return graph, target\n",
        "\n",
        "def precompute_graphs(df):\n",
        "    \"\"\" Pre-computes and caches graph objects for faster loading. \"\"\"\n",
        "    print(\"Pre-computing and caching graphs...\")\n",
        "    for i, row in tqdm(df.iterrows(), total=len(df)):\n",
        "        smiles, idx = row['SMILES'], row['id']\n",
        "        graph_path = os.path.join(config.GRAPH_CACHE_DIR, f\"graph_{idx}.pt\")\n",
        "        if not os.path.exists(graph_path):\n",
        "            graph = smiles_to_graph(smiles, idx)\n",
        "            if graph:\n",
        "                torch.save(graph, graph_path)\n",
        "\n",
        "# ==============================================================================\n",
        "# Step 4: GNN Model Architecture\n",
        "# ==============================================================================\n",
        "\n",
        "class PolymerGNN(nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels, num_layers, heads, dropout):\n",
        "        super(PolymerGNN, self).__init__()\n",
        "        self.convs = nn.ModuleList()\n",
        "        self.convs.append(GATv2Conv(in_channels, hidden_channels, heads=heads, dropout=dropout, concat=True))\n",
        "        for _ in range(num_layers - 2):\n",
        "            self.convs.append(GATv2Conv(hidden_channels * heads, hidden_channels, heads=heads, dropout=dropout, concat=True))\n",
        "        self.convs.append(GATv2Conv(hidden_channels * heads, hidden_channels, heads=1, dropout=dropout, concat=False))\n",
        "\n",
        "        self.prediction_heads = nn.ModuleList([\n",
        "            nn.Sequential(\n",
        "                nn.Linear(hidden_channels, hidden_channels // 2),\n",
        "                nn.ReLU(),\n",
        "                nn.Dropout(p=dropout),\n",
        "                nn.Linear(hidden_channels // 2, 1)\n",
        "            ) for _ in range(out_channels)\n",
        "        ])\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
        "        for i, conv in enumerate(self.convs):\n",
        "            x = conv(x, edge_index)\n",
        "            if i < len(self.convs) - 1:\n",
        "                x = torch.relu(x)\n",
        "        x = global_mean_pool(x, batch)\n",
        "        outputs = [head(x) for head in self.prediction_heads]\n",
        "        return torch.cat(outputs, dim=1)\n",
        "\n",
        "# ==============================================================================\n",
        "# Step 5: Custom Loss Function (Weighted MAE)\n",
        "# ==============================================================================\n",
        "\n",
        "class WeightedMAELoss(nn.Module):\n",
        "    def __init__(self, weights):\n",
        "        super(WeightedMAELoss, self).__init__()\n",
        "        self.weights = torch.tensor(weights, dtype=torch.float).to(config.DEVICE)\n",
        "\n",
        "    def forward(self, predictions, targets):\n",
        "        mask = ~torch.isnan(targets)\n",
        "        if not mask.any(): return torch.tensor(0.0, device=predictions.device)\n",
        "        absolute_errors = torch.abs(predictions[mask] - targets[mask])\n",
        "        weighted_errors = absolute_errors * self.weights.repeat(predictions.shape[0])[mask.flatten()]\n",
        "        return torch.mean(weighted_errors)\n",
        "\n",
        "def get_wmae_weights(df_train):\n",
        "    \"\"\" Calculates the weights for the wMAE loss function based on the full training set.\"\"\"\n",
        "    K = len(config.TARGET_PROPERTIES)\n",
        "    ni = df_train[config.TARGET_PROPERTIES].count().values\n",
        "    ri = df_train[config.TARGET_PROPERTIES].max().values - df_train[config.TARGET_PROPERTIES].min().values\n",
        "    ri[ri == 0] = 1\n",
        "    term1 = 1 / ri\n",
        "    term2_sum = np.sum(1 / np.sqrt(ni))\n",
        "    term2 = K * (1 / np.sqrt(ni)) / term2_sum\n",
        "    weights = term1 * term2\n",
        "    print(\"Calculated wMAE weights:\")\n",
        "    for prop, w in zip(config.TARGET_PROPERTIES, weights): print(f\"  {prop}: {w:.4f}\")\n",
        "    return weights\n",
        "\n",
        "# ==============================================================================\n",
        "# Step 6: Training and Evaluation Loops\n",
        "# ==============================================================================\n",
        "\n",
        "def train_one_epoch(model, dataloader, criterion, optimizer, device):\n",
        "    \"\"\" Trains the model for one epoch. \"\"\"\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for batch_graphs, batch_targets in tqdm(dataloader, desc=\"Training\"):\n",
        "        batch_graphs, batch_targets = batch_graphs.to(device), batch_targets.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        predictions = model(batch_graphs)\n",
        "        loss = criterion(predictions, batch_targets)\n",
        "        if not torch.isnan(loss):\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "    return total_loss / len(dataloader)\n",
        "\n",
        "def evaluate_one_epoch(model, dataloader, criterion, device):\n",
        "    \"\"\" Evaluates the model on the validation set for one epoch. \"\"\"\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for batch_graphs, batch_targets in tqdm(dataloader, desc=\"Validating\"):\n",
        "            batch_graphs, batch_targets = batch_graphs.to(device), batch_targets.to(device)\n",
        "            predictions = model(batch_graphs)\n",
        "            loss = criterion(predictions, batch_targets)\n",
        "            if not torch.isnan(loss):\n",
        "                total_loss += loss.item()\n",
        "    return total_loss / len(dataloader)\n",
        "\n",
        "def predict(model, dataloader, device):\n",
        "    \"\"\" Makes predictions on the test set. \"\"\"\n",
        "    model.eval()\n",
        "    all_predictions = []\n",
        "    with torch.no_grad():\n",
        "        for batch_graphs, _ in tqdm(dataloader, desc=\"Predicting\"):\n",
        "            batch_graphs = batch_graphs.to(device)\n",
        "            predictions = model(batch_graphs)\n",
        "            all_predictions.append(predictions.cpu().numpy())\n",
        "    return np.vstack(all_predictions)\n",
        "\n",
        "# ==============================================================================\n",
        "# Step 7: Main Execution Block\n",
        "# ==============================================================================\n",
        "\n",
        "def main():\n",
        "    print(\"--- Starting Polymer Property Prediction ---\")\n",
        "\n",
        "    # Load data\n",
        "    print(\"Loading data...\")\n",
        "    full_train_df = pd.read_csv(config.TRAIN_PATH)\n",
        "    test_df = pd.read_csv(config.TEST_PATH)\n",
        "\n",
        "    # Pre-compute graphs for all data splits\n",
        "    if config.PRECOMPUTE_GRAPHS:\n",
        "        precompute_graphs(full_train_df)\n",
        "        precompute_graphs(test_df)\n",
        "\n",
        "    # NEW: Split training data into training and validation sets\n",
        "    print(f\"Splitting data into {1-config.VALIDATION_SPLIT:.0%} training and {config.VALIDATION_SPLIT:.0%} validation...\")\n",
        "    val_df = full_train_df.sample(frac=config.VALIDATION_SPLIT, random_state=42)\n",
        "    train_df = full_train_df.drop(val_df.index)\n",
        "    print(f\"Training set size: {len(train_df)}, Validation set size: {len(val_df)}\")\n",
        "\n",
        "    # Prepare datasets and dataloaders\n",
        "    print(\"Preparing datasets...\")\n",
        "    train_targets = train_df[config.TARGET_PROPERTIES].values\n",
        "    val_targets = val_df[config.TARGET_PROPERTIES].values\n",
        "\n",
        "    train_dataset = PolymerDataset(train_df, targets=train_targets)\n",
        "    val_dataset = PolymerDataset(val_df, targets=val_targets)\n",
        "    test_dataset = PolymerDataset(test_df, is_train=False)\n",
        "\n",
        "    train_loader = PyGDataLoader(train_dataset, batch_size=config.BATCH_SIZE, shuffle=True, num_workers=2, pin_memory=True)\n",
        "    val_loader = PyGDataLoader(val_dataset, batch_size=config.BATCH_SIZE, shuffle=False, num_workers=2)\n",
        "    test_loader = PyGDataLoader(test_dataset, batch_size=config.BATCH_SIZE, shuffle=False, num_workers=2)\n",
        "\n",
        "    # Determine feature dimensions\n",
        "    sample_graph, _ = train_dataset[0]\n",
        "    in_channels = sample_graph.x.shape[1]\n",
        "\n",
        "    # Initialize model, loss, and optimizer\n",
        "    print(\"Initializing model...\")\n",
        "    model = PolymerGNN(\n",
        "        in_channels=in_channels,\n",
        "        hidden_channels=config.HIDDEN_CHANNELS,\n",
        "        out_channels=config.NUM_TARGETS,\n",
        "        num_layers=config.NUM_GNN_LAYERS,\n",
        "        heads=config.NUM_ATTENTION_HEADS,\n",
        "        dropout=config.DROPOUT_RATE\n",
        "    ).to(config.DEVICE)\n",
        "    print(f\"Model has {sum(p.numel() for p in model.parameters() if p.requires_grad):,} trainable parameters.\")\n",
        "\n",
        "    # Calculate weights on the full training set\n",
        "    weights = get_wmae_weights(full_train_df)\n",
        "    criterion = WeightedMAELoss(weights)\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=config.LEARNING_RATE, weight_decay=config.WEIGHT_DECAY)\n",
        "    # NEW: Scheduler now monitors validation loss\n",
        "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.5, patience=3, verbose=True)\n",
        "\n",
        "    # Training loop with validation\n",
        "    print(\"\\n--- Starting Training ---\")\n",
        "    best_val_loss = float('inf')\n",
        "    for epoch in range(config.EPOCHS):\n",
        "        avg_train_loss = train_one_epoch(model, train_loader, criterion, optimizer, config.DEVICE)\n",
        "        avg_val_loss = evaluate_one_epoch(model, val_loader, criterion, config.DEVICE)\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{config.EPOCHS} | Train Loss: {avg_train_loss:.6f} | Val Loss: {avg_val_loss:.6f}\")\n",
        "\n",
        "        # NEW: Update scheduler and save model based on validation loss\n",
        "        scheduler.step(avg_val_loss)\n",
        "        if avg_val_loss < best_val_loss:\n",
        "            best_val_loss = avg_val_loss\n",
        "            torch.save(model.state_dict(), 'best_model.pth')\n",
        "            print(f\"Saved new best model with validation loss {best_val_loss:.6f}\")\n",
        "\n",
        "        gc.collect()\n",
        "        if torch.cuda.is_available(): torch.cuda.empty_cache()\n",
        "\n",
        "    # Inference\n",
        "    print(\"\\n--- Starting Prediction on Test Set ---\")\n",
        "    model.load_state_dict(torch.load('best_model.pth'))\n",
        "    predictions = predict(model, test_loader, config.DEVICE)\n",
        "\n",
        "    # Create submission file\n",
        "    print(\"Creating submission file...\")\n",
        "    submission_df = pd.DataFrame(predictions, columns=config.TARGET_PROPERTIES)\n",
        "    submission_df.insert(0, 'id', test_df['id'])\n",
        "    submission_df.to_csv(config.SUBMISSION_PATH, index=False)\n",
        "\n",
        "    print(f\"Submission file created at: {config.SUBMISSION_PATH}\")\n",
        "    print(submission_df.head())\n",
        "    print(\"--- Process Complete ---\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    if not os.path.exists(config.TRAIN_PATH) or not os.path.exists(config.TEST_PATH):\n",
        "        print(f\"Error: Make sure '{config.TRAIN_PATH}' and '{config.TEST_PATH}' are present.\")\n",
        "        print(\"Creating dummy data files for demonstration purposes.\")\n",
        "        pd.DataFrame({\n",
        "            'id': range(100), 'SMILES': ['CCO']*100, 'Tg': np.random.rand(100)*100,\n",
        "            'FFV': np.random.rand(100), 'Tc': np.random.rand(100),\n",
        "            'Density': np.random.rand(100), 'Rg': np.random.rand(100)*10\n",
        "        }).to_csv(config.TRAIN_PATH, index=False)\n",
        "        pd.DataFrame({'id': range(100, 110), 'SMILES': ['CCN']*10}).to_csv(config.TEST_PATH, index=False)\n",
        "    main()"
      ],
      "metadata": {
        "id": "Q57J_uDAWTAs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rdkit torch_geometric"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m4naz__UPOpq",
        "outputId": "49ce9fc7-94b2-4a7f-ee32-05ed8b8ae80b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rdkit\n",
            "  Downloading rdkit-2025.3.3-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (4.0 kB)\n",
            "Collecting torch_geometric\n",
            "  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/63.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from rdkit) (2.0.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from rdkit) (11.2.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.11.15)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2025.3.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.1.6)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.2.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (4.67.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.20.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch_geometric) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (2025.6.15)\n",
            "Downloading rdkit-2025.3.3-cp311-cp311-manylinux_2_28_x86_64.whl (34.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.9/34.9 MB\u001b[0m \u001b[31m61.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m56.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: rdkit, torch_geometric\n",
            "Successfully installed rdkit-2025.3.3 torch_geometric-2.6.1\n"
          ]
        }
      ]
    }
  ]
}